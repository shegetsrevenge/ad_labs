{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from stack_data->ipython) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кожної із адміністративних одиниць України завантажити тестові структуровані файли, що містять значення VHI-індексу. \n",
    "Ця процедура має бути автоматизована, параметром процедури має бути індекс (номер) області. \n",
    "При зберіганні файлу до його імені потрібно додати дату та час завантаження.\n",
    "\n",
    "Передбачити повторні запуски скрипту, довантаження нових даних та колізію\n",
    "даних;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл збережено: region_1_VHI_11-05-2025_16-33-07.csv\n",
      "Файл збережено: region_2_VHI_11-05-2025_16-33-09.csv\n",
      "Файл збережено: region_3_VHI_11-05-2025_16-33-10.csv\n",
      "Файл збережено: region_4_VHI_11-05-2025_16-33-14.csv\n",
      "Файл збережено: region_5_VHI_11-05-2025_16-33-15.csv\n",
      "Файл збережено: region_6_VHI_11-05-2025_16-33-16.csv\n",
      "Файл збережено: region_7_VHI_11-05-2025_16-33-17.csv\n",
      "Файл збережено: region_8_VHI_11-05-2025_16-33-18.csv\n",
      "Файл збережено: region_9_VHI_11-05-2025_16-33-19.csv\n",
      "Файл збережено: region_10_VHI_11-05-2025_16-33-20.csv\n",
      "Файл збережено: region_11_VHI_11-05-2025_16-33-21.csv\n",
      "Файл збережено: region_12_VHI_11-05-2025_16-33-22.csv\n",
      "Файл збережено: region_13_VHI_11-05-2025_16-33-24.csv\n",
      "Файл збережено: region_14_VHI_11-05-2025_16-33-25.csv\n",
      "Файл збережено: region_15_VHI_11-05-2025_16-33-26.csv\n",
      "Файл збережено: region_16_VHI_11-05-2025_16-33-27.csv\n",
      "Файл збережено: region_17_VHI_11-05-2025_16-33-28.csv\n",
      "Файл збережено: region_18_VHI_11-05-2025_16-33-29.csv\n",
      "Файл збережено: region_19_VHI_11-05-2025_16-33-30.csv\n",
      "Файл збережено: region_20_VHI_11-05-2025_16-33-31.csv\n",
      "Файл збережено: region_21_VHI_11-05-2025_16-33-33.csv\n",
      "Файл збережено: region_22_VHI_11-05-2025_16-33-34.csv\n",
      "Файл збережено: region_23_VHI_11-05-2025_16-33-35.csv\n",
      "Файл збережено: region_24_VHI_11-05-2025_16-33-36.csv\n",
      "Файл збережено: region_25_VHI_11-05-2025_16-33-37.csv\n",
      "Файл збережено: region_26_VHI_11-05-2025_16-33-38.csv\n",
      "Файл збережено: region_27_VHI_11-05-2025_16-33-39.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request   # Модуль для роботи з HTTP-запитами\n",
    "import hashlib          # Модуль для обчислення хешів (SHA-256)\n",
    "import os               # Модуль для роботи з файловою системою\n",
    "import re               # Модуль для регулярних виразів\n",
    "from datetime import datetime  # Для формування поточної дати/часу у назві файлу\n",
    "\n",
    "# Папка, у яку зберігатимуться CSV-файли з даними\n",
    "SAVE_FOLDER = \"CSV_Files\"\n",
    "\n",
    "# Якщо папка не існує — створюємо її\n",
    "if not os.path.exists(SAVE_FOLDER):\n",
    "    os.makedirs(SAVE_FOLDER)\n",
    "\n",
    "def compute_sha256(content):\n",
    "    \"\"\"\n",
    "    Обчислює SHA-256 хеш для вмісту (рядка).\n",
    "    Це використовується для перевірки, чи дублюється файл.\n",
    "    \"\"\"\n",
    "    return hashlib.sha256(content.encode('utf-8')).hexdigest()\n",
    "\n",
    "def fetch_vhi(region_number):\n",
    "    \"\"\"\n",
    "    Завантажує дані VHI для однієї області за її номером.\n",
    "    Якщо такі дані вже існують у вигляді ідентичного файлу — не зберігає повторно.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Формування URL для запиту до сервера NOAA\n",
    "    url = (\n",
    "        f\"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php\"\n",
    "        f\"?country=UKR&provinceID={region_number}&year1=1981&year2=2024&type=Mean\"\n",
    "    )\n",
    "\n",
    "    # Створення унікального імені файлу на основі поточного часу\n",
    "    timestamp = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "    filename = f\"region_{region_number}_VHI_{timestamp}.csv\"\n",
    "    filepath = os.path.join(SAVE_FOLDER, filename)\n",
    "\n",
    "    try:\n",
    "        # Відправлення запиту та отримання HTML-відповіді від сервера\n",
    "        response = urllib.request.urlopen(url)\n",
    "        raw_html = response.read().decode('utf-8', errors='replace')\n",
    "\n",
    "        # Пошук CSV-даних усередині HTML-тегів <pre>...</pre>\n",
    "        match = re.search(r\"<pre>(.*?)</pre>\", raw_html, re.DOTALL)\n",
    "        if not match:\n",
    "            print(f\"Дані не знайдено для області {region_number}\")\n",
    "            return\n",
    "\n",
    "        # Вилучення CSV-даних з тегу\n",
    "        csv_data = match.group(1).strip()\n",
    "\n",
    "        # Обчислення хешу нових CSV-даних\n",
    "        new_hash = compute_sha256(csv_data)\n",
    "\n",
    "        # Перевірка на дублікати: порівнюємо хеші з уже наявними файлами\n",
    "        for old_file in os.listdir(SAVE_FOLDER):\n",
    "            if not old_file.endswith('.csv'):\n",
    "                continue  # Пропускаємо не-CSV файли\n",
    "            old_path = os.path.join(SAVE_FOLDER, old_file)\n",
    "            with open(old_path, 'r', encoding='utf-8') as f:\n",
    "                old_data = f.read()\n",
    "                if compute_sha256(old_data) == new_hash:\n",
    "                    print(f\"Дублікат знайдено для області {region_number}. Файл не буде збережено.\")\n",
    "                    return  # Не зберігати дублікати\n",
    "\n",
    "        # Якщо дубліката не знайдено — зберігаємо CSV-файл\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(csv_data)\n",
    "\n",
    "        print(f\"Файл збережено: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Вивід повідомлення, якщо щось пішло не так\n",
    "        print(f\"Помилка при завантаженні для області {region_number}: {e}\")\n",
    "\n",
    "# Завантаження VHI-даних для всіх 27 областей України (індекси від 1 до 27 включно)\n",
    "for region_id in range(1, 28):\n",
    "    fetch_vhi(region_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Шлях до теки з CSV-файлами\n",
    "folder_path = 'CSV_Files'  # заміни на свій шлях\n",
    "\n",
    "# Порожній список для збору всіх DataFrame\n",
    "all_data = []\n",
    "\n",
    "# Перебір усіх CSV у теці\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Витягуємо назву регіону з імені файлу (без .csv)\n",
    "        region_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Додаємо колонку з назвою області\n",
    "        df['region'] = region_name\n",
    "\n",
    "        # Додаємо у загальний список\n",
    "        all_data.append(df)\n",
    "\n",
    "# Об'єднуємо всі таблиці в одну\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Зберігаємо об'єднаний файл\n",
    "combined_df.to_csv('all_regions_combined.csv', index=False)\n",
    "\n",
    "print(\"✅ Успішно об'єднано! Збережено як all_regions_combined.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зчитати завантажені текстові файли у фрейм\n",
    "(https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) (детальніше\n",
    "про роботу із фреймами буде розказано у подальших лабораторних роботах).\n",
    "Імена стовбців фрейму мають бути змістовними та легкими для сприйняття (не\n",
    "повинно бути спеціалізованих символів, пробілів тощо). Ця задача має бути\n",
    "реалізована у вигляді окремої процедури, яка на вхід приймає шлях до\n",
    "директорії, в якій зберігаються файли;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8464\\3985729364.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_df = pd.concat([result_df, data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дані об'єднано та збережено у 'full.csv'\n",
      "Перші 10 рядків:\n",
      "   Year Week    SMN     SMT    VCI    TCI    VHI PROVINCE_ID\n",
      "0  1982    1  0.053  260.31  45.01  39.46  42.23           1\n",
      "1  1982    2  0.054  262.29  46.83  31.75  39.29           1\n",
      "2  1982    3  0.055  263.82  48.13  27.24  37.68           1\n",
      "3  1982    4  0.053  265.33  46.09  23.91  35.00           1\n",
      "4  1982    5  0.050  265.66  41.46  26.65  34.06           1\n",
      "5  1982    6  0.048  266.55  36.56  29.46  33.01           1\n",
      "6  1982    7  0.048  267.84  32.17  31.14  31.65           1\n",
      "7  1982    8  0.050  269.30  30.30  32.50  31.40           1\n",
      "8  1982    9  0.052  270.75  28.23  35.22  31.73           1\n",
      "9  1982   10  0.056  272.73  25.25  37.63  31.44           1\n",
      "Останні 10 рядків:\n",
      "       Year Week    SMN     SMT    VCI    TCI    VHI PROVINCE_ID\n",
      "59012  2024   43  0.259  281.45  79.71  17.45  48.58          27\n",
      "59013  2024   44  0.229  279.41  76.74  13.33  45.04          27\n",
      "59014  2024   45  0.206  278.07  77.64   8.70  43.17          27\n",
      "59015  2024   46  0.177  275.95  74.84  10.23  42.53          27\n",
      "59016  2024   47  0.149  273.20  71.22  16.89  44.05          27\n",
      "59017  2024   48  0.128  270.55  64.97  25.53  45.25          27\n",
      "59018  2024   49  0.115  269.06  60.12  27.24  43.68          27\n",
      "59019  2024   50  0.104  267.75  55.24  25.89  40.57          27\n",
      "59020  2024   51  0.094  266.45  51.16  24.29  37.72          27\n",
      "59021  2024   52  0.093  266.38  54.22  21.11  37.66          27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Папка з CSV-файлами\n",
    "DATA_DIR = \"CSV_Files\"\n",
    "RESULT_FILE = \"full.csv\"\n",
    "\n",
    "# Очікувані назви колонок\n",
    "COLUMNS = [\"Year\", \"Week\", \"SMN\", \"SMT\", \"VCI\", \"TCI\", \"VHI\", \"PROVINCE_ID\"]\n",
    "\n",
    "# Ініціалізуємо фінальний DataFrame\n",
    "result_df = pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "# Отримуємо список лише тих CSV-файлів, які містять числа (ідентифікатори)\n",
    "raw_files = os.listdir(DATA_DIR)\n",
    "target_files = []\n",
    "for file in raw_files:\n",
    "    if file.endswith(\".csv\") and re.search(r'\\d+', file):\n",
    "        target_files.append(file)\n",
    "\n",
    "# Сортуємо список файлів за першим числом (ідентифікатор області)\n",
    "sorted_files = sorted(target_files, key=lambda name: int(re.findall(r'\\d+', name)[0]))\n",
    "\n",
    "# Обробляємо кожен файл\n",
    "for file in sorted_files:\n",
    "    file_path = os.path.join(DATA_DIR, file)\n",
    "\n",
    "    try:\n",
    "        # Витягуємо ідентифікатор області\n",
    "        match = re.findall(r'\\d+', file)\n",
    "        province = int(match[0]) if match else None\n",
    "        if province is None:\n",
    "            continue\n",
    "\n",
    "        # Зчитуємо дані\n",
    "        data = pd.read_csv(file_path, skiprows=0, names=COLUMNS)\n",
    "\n",
    "        # Очищаємо колонку 'Year' від HTML-тегів\n",
    "        data[\"Year\"] = data[\"Year\"].astype(str).str.replace(r\"<tt><pre>|</pre></tt>\", \"\", regex=True)\n",
    "        data[\"Year\"] = pd.to_numeric(data[\"Year\"], errors=\"coerce\")\n",
    "        data[\"Week\"] = pd.to_numeric(data[\"Week\"], errors=\"coerce\")\n",
    "\n",
    "        # Видаляємо рядки з некоректними значеннями\n",
    "        data.dropna(subset=[\"Year\", \"Week\"], inplace=True)\n",
    "        data = data.astype({\"Year\": int, \"Week\": int})\n",
    "\n",
    "        # Встановлюємо колонку PROVINCE_ID\n",
    "        data[\"PROVINCE_ID\"] = province\n",
    "\n",
    "        # Фільтруємо негативні або відсутні значення VHI\n",
    "        data = data[data[\"VHI\"] != -1].dropna()\n",
    "\n",
    "        # Додаємо до підсумкового DataFrame\n",
    "        result_df = pd.concat([result_df, data], ignore_index=True)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Не вдалося обробити файл {file}: {err}\")\n",
    "\n",
    "# Збереження результату\n",
    "result_df.to_csv(RESULT_FILE, index=False)\n",
    "\n",
    "# Вивід результату\n",
    "print(f\"Дані об'єднано та збережено у '{RESULT_FILE}'\")\n",
    "print(\"Перші 10 рядків:\")\n",
    "print(result_df.head(10))\n",
    "print(\"Останні 10 рядків:\")\n",
    "print(result_df.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізувати окрему процедуру, яка змінить індекси областей, які використані на\n",
    "порталі NOAA (за англійською абеткою) на наступні, за українською (виключно\n",
    "старі індекси на нові):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оновлений файл збережено: Updated_Provinces.csv\n",
      "Перші 10 рядків оновленого файлу:\n",
      "   Year  Week    SMN     SMT    VCI    TCI    VHI  PROVINCE_ID\n",
      "0  1982     1  0.053  260.31  45.01  39.46  42.23           21\n",
      "1  1982     2  0.054  262.29  46.83  31.75  39.29           21\n",
      "2  1982     3  0.055  263.82  48.13  27.24  37.68           21\n",
      "3  1982     4  0.053  265.33  46.09  23.91  35.00           21\n",
      "4  1982     5  0.050  265.66  41.46  26.65  34.06           21\n",
      "5  1982     6  0.048  266.55  36.56  29.46  33.01           21\n",
      "6  1982     7  0.048  267.84  32.17  31.14  31.65           21\n",
      "7  1982     8  0.050  269.30  30.30  32.50  31.40           21\n",
      "8  1982     9  0.052  270.75  28.23  35.22  31.73           21\n",
      "9  1982    10  0.056  272.73  25.25  37.63  31.44           21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_province_ids(df):\n",
    "\n",
    "    # Мапінг старих індексів (NOAA) на нові (українська абетка)\n",
    "    province_mapping = {\n",
    "        1: 21, 2: 24, 3: 23, 4: 26, 5: 3, 6: 4, 7: 8, 8: 19, 9: 20, 10: 22,\n",
    "        11: 9, 12: 10, 13: 11, 14: 12, 15: 13, 16: 14, 17: 15, 18: 16, 19: 17,\n",
    "        20: 18, 21: 1, 22: 2, 23: 6, 24: 7, 25: 5, 26: 25, 27: 27\n",
    "\n",
    "        }\n",
    "    \n",
    "    # Переконуємося, що колонка \"PROVINCE_ID\" є у DataFrame\n",
    "    if \"PROVINCE_ID\" not in df.columns:\n",
    "        print(\"Колонка 'PROVINCE_ID' не знайдена у DataFrame!\")\n",
    "        return df\n",
    "\n",
    "    # Оновлення значень\n",
    "    df[\"PROVINCE_ID\"] = df[\"PROVINCE_ID\"].map(province_mapping)\n",
    "\n",
    "    # Приведення стовпця \"Week\" до числового типу та обробка некоректних значень\n",
    "    if 'Week' in df.columns:\n",
    "        df['Week'] = pd.to_numeric(df['Week'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Припустимо, що дані зчитуються з файлу CSV\n",
    "input_file = \"full.csv\"\n",
    "output_file = \"Updated_Provinces.csv\"\n",
    "\n",
    "# Зчитуємо дані з файлу\n",
    "combined_data = pd.read_csv(input_file)\n",
    "\n",
    "# Оновлення індексів у `combined_data`\n",
    "combined_data = update_province_ids(combined_data)\n",
    "\n",
    "# Збереження у файл\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Виведення результату\n",
    "print(f\"Оновлений файл збережено: {output_file}\")\n",
    "print(\"Перші 10 рядків оновленого файлу:\")\n",
    "print(combined_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реалізувати процедури для формування вибірок наступного виду (включаючи елементи аналізу):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o Ряд VHI для області за вказаний рік;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Отримати ряд VHI для області за вказаний рік"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дані VHI для Вінницької області (ID=21) у 1997 році:\n",
      "     Year  Week    VHI\n",
      "750  1997     1  30.59\n",
      "751  1997     2  31.96\n",
      "752  1997     3  33.30\n",
      "753  1997     4  33.85\n",
      "754  1997     5  36.83\n",
      "755  1997     6  39.52\n",
      "756  1997     7  38.44\n",
      "757  1997     8  36.73\n",
      "758  1997     9  36.21\n",
      "759  1997    10  35.20\n",
      "760  1997    11  32.23\n",
      "761  1997    12  30.84\n",
      "762  1997    13  31.11\n",
      "763  1997    14  30.91\n",
      "764  1997    15  31.23\n",
      "765  1997    16  33.55\n",
      "766  1997    17  37.09\n",
      "767  1997    18  42.06\n",
      "768  1997    19  46.30\n",
      "769  1997    20  47.73\n",
      "770  1997    21  51.82\n",
      "771  1997    22  57.77\n",
      "772  1997    23  62.80\n",
      "773  1997    24  68.77\n",
      "774  1997    25  73.78\n",
      "775  1997    26  76.53\n",
      "776  1997    27  79.05\n",
      "777  1997    28  81.06\n",
      "778  1997    29  81.70\n",
      "779  1997    30  82.47\n",
      "780  1997    31  82.28\n",
      "781  1997    32  82.45\n",
      "782  1997    33  82.96\n",
      "783  1997    34  83.20\n",
      "784  1997    35  83.70\n",
      "785  1997    36  83.44\n",
      "786  1997    37  82.34\n",
      "787  1997    38  80.51\n",
      "788  1997    39  77.40\n",
      "789  1997    40  73.30\n",
      "790  1997    41  68.39\n",
      "791  1997    42  64.24\n",
      "792  1997    43  61.87\n",
      "793  1997    44  56.65\n",
      "794  1997    45  50.40\n",
      "795  1997    46  45.63\n",
      "796  1997    47  43.90\n",
      "797  1997    48  45.75\n",
      "798  1997    49  48.38\n",
      "799  1997    50  49.60\n",
      "800  1997    51  49.36\n",
      "801  1997    52  47.95\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_for_region(df, province_id, year=None):\n",
    "\n",
    "    # Перевірка наявності колонок\n",
    "    required_columns = [\"PROVINCE_ID\", \"Year\", \"Week\", \"VHI\"]\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Попередження: У DataFrame відсутні колонки {missing_cols}\")\n",
    "        return pd.DataFrame(columns=required_columns)\n",
    "    \n",
    "    # Фільтрація даних\n",
    "    mask = df[\"PROVINCE_ID\"] == province_id\n",
    "    if year is not None:\n",
    "        mask &= df[\"Year\"] == year\n",
    "    \n",
    "    result = df.loc[mask, [\"Year\", \"Week\", \"VHI\"]]\n",
    "    \n",
    "    # Сортування за роком та тижнем (якщо дані є)\n",
    "    if not result.empty:\n",
    "        result = result.sort_values([\"Year\", \"Week\"])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Приклад використання\n",
    "vhi_data = get_vhi_for_region(combined_data, province_id=21, year=1997)\n",
    "print(\"Дані VHI для Вінницької області (ID=21) у 1997 році:\")\n",
    "print(vhi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Пошук екстремумів (min, max), середнього, медіани"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статистика VHI:\n",
      "   PROVINCE_ID  Year    min    max       mean  median\n",
      "0            2  1997  32.29  75.08  53.080192  50.525\n",
      "1            2  2007  35.04  57.10  48.585769  49.945\n",
      "2           27  1997  44.41  75.39  57.640000  54.540\n",
      "3           27  2007  39.81  62.78  50.675962  50.745\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_statistics(df, province_ids, years=None):\n",
    "\n",
    "    # Перевірка наявності колонок\n",
    "    required_columns = [\"PROVINCE_ID\", \"Year\", \"VHI\"]\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Попередження: У DataFrame відсутні колонки {missing_cols}\")\n",
    "        return pd.DataFrame(columns=required_columns + [\"min\", \"max\", \"mean\", \"median\"])\n",
    "    \n",
    "    # Фільтрація даних\n",
    "    mask = df[\"PROVINCE_ID\"].isin(province_ids)\n",
    "    if years is not None:\n",
    "        mask &= df[\"Year\"].isin(years)\n",
    "    \n",
    "    filtered_df = df.loc[mask]\n",
    "    \n",
    "    # Обчислення статистики\n",
    "    if filtered_df.empty:\n",
    "        print(\"Попередження: Немає даних для вказаних параметрів\")\n",
    "        return pd.DataFrame(columns=required_columns + [\"min\", \"max\", \"mean\", \"median\"])\n",
    "    \n",
    "    stats = filtered_df.groupby([\"PROVINCE_ID\", \"Year\"])[\"VHI\"] \\\n",
    "                      .agg([\"min\", \"max\", \"mean\", \"median\"]) \\\n",
    "                      .reset_index()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Приклад використання\n",
    "vhi_stats = get_vhi_statistics(\n",
    "    combined_data, \n",
    "    province_ids=[2, 27],  \n",
    "    years=[1997, 2007]     \n",
    ")\n",
    "\n",
    "print(\"Статистика VHI:\")\n",
    "print(vhi_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Отримати ряд VHI за вказаний діапазон років для вказаних областей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отримання даних...\n",
      "Знайдено дані для областей з ID: [np.int64(3), np.int64(7), np.int64(12)]\n",
      "Діапазон років: 1990 - 2020\n",
      "Кількість записів: 4719\n",
      "\n",
      "Перші 10 рядків даних:\n",
      "      PROVINCE_ID  Year  Week    VHI\n",
      "9149            3  1990     1  40.88\n",
      "9150            3  1990     2  41.08\n",
      "9151            3  1990     3  41.28\n",
      "9152            3  1990     4  41.70\n",
      "9153            3  1990     5  41.75\n",
      "9154            3  1990     6  42.43\n",
      "9155            3  1990     7  44.36\n",
      "9156            3  1990     8  45.45\n",
      "9157            3  1990     9  46.07\n",
      "9158            3  1990    10  51.72\n",
      "\n",
      "Дані для області ID=3:\n",
      "      PROVINCE_ID  Year  Week    VHI\n",
      "9149            3  1990     1  40.88\n",
      "9150            3  1990     2  41.08\n",
      "9151            3  1990     3  41.28\n",
      "9152            3  1990     4  41.70\n",
      "9153            3  1990     5  41.75\n",
      "\n",
      "Дані для області ID=7:\n",
      "       PROVINCE_ID  Year  Week    VHI\n",
      "50683            7  1990     1  39.52\n",
      "50684            7  1990     2  40.34\n",
      "50685            7  1990     3  41.14\n",
      "50686            7  1990     4  41.18\n",
      "50687            7  1990     5  41.26\n",
      "\n",
      "Дані для області ID=12:\n",
      "       PROVINCE_ID  Year  Week    VHI\n",
      "28823           12  1990     1  29.82\n",
      "28824           12  1990     2  29.12\n",
      "28825           12  1990     3  31.67\n",
      "28826           12  1990     4  33.62\n",
      "28827           12  1990     5  34.07\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_by_year_range(df, province_ids, start_year, end_year, include_stats=False, verbose=True):\n",
    "\n",
    "    # Перевірка наявності необхідних колонок\n",
    "    required_cols = ['PROVINCE_ID', 'Year', 'Week', 'VHI']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        msg = f\"Попередження: Відсутні колонки: {missing_cols}\"\n",
    "        if verbose: print(msg)\n",
    "        return pd.DataFrame(columns=required_cols)\n",
    "    \n",
    "    # Перевірка коректності років\n",
    "    if start_year > end_year:\n",
    "        msg = \"Попередження: Початковий рік більший за кінцевий. Буде поміняно місцями.\"\n",
    "        if verbose: print(msg)\n",
    "        start_year, end_year = end_year, start_year\n",
    "    \n",
    "    # Перевірка наявності вказаних областей\n",
    "    existing_provinces = df['PROVINCE_ID'].unique()\n",
    "    missing_provinces = [pid for pid in province_ids if pid not in existing_provinces]\n",
    "    \n",
    "    if missing_provinces and verbose:\n",
    "        print(f\"Попередження: Відсутні дані для областей з ID: {missing_provinces}\")\n",
    "    \n",
    "    # Фільтрація даних\n",
    "    mask = (df['PROVINCE_ID'].isin(province_ids)) & (df['Year'].between(start_year, end_year))\n",
    "    result = df.loc[mask, required_cols]\n",
    "    \n",
    "    if result.empty:\n",
    "        msg = f\"Попередження: Немає даних для областей {province_ids} у період {start_year}-{end_year}\"\n",
    "        if verbose: print(msg)\n",
    "        return pd.DataFrame(columns=required_cols)\n",
    "    \n",
    "    # Сортування результатів\n",
    "    result = result.sort_values(['PROVINCE_ID', 'Year', 'Week'])\n",
    "    \n",
    "    # Додаткова інформація про наявні області\n",
    "    if verbose:\n",
    "        present_provinces = result['PROVINCE_ID'].unique()\n",
    "        print(f\"Знайдено дані для областей з ID: {sorted(present_provinces)}\")\n",
    "        print(f\"Діапазон років: {result['Year'].min()} - {result['Year'].max()}\")\n",
    "        print(f\"Кількість записів: {len(result)}\")\n",
    "    \n",
    "    # Додаткова статистика\n",
    "    if include_stats:\n",
    "        stats = result.groupby(['PROVINCE_ID', 'Year'])['VHI'] \\\n",
    "                     .agg(['min', 'max', 'mean', 'median']) \\\n",
    "                     .reset_index()\n",
    "        return {'data': result, 'stats': stats}\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Приклад використання:\n",
    "province_ids = [3, 7, 12] \n",
    "start_year = 1990\n",
    "end_year = 2000\n",
    "\n",
    "print(\"Отримання даних...\")\n",
    "vhi_data = get_vhi_by_year_range(combined_data, province_ids, start_year, end_year, verbose=True)\n",
    "\n",
    "if not vhi_data.empty:\n",
    "    print(\"\\nПерші 10 рядків даних:\")\n",
    "    print(vhi_data.head(10))\n",
    "    \n",
    "    # Виводимо дані для кожної області окремо\n",
    "    for province in province_ids:\n",
    "        province_data = vhi_data[vhi_data['PROVINCE_ID'] == province]\n",
    "        if not province_data.empty:\n",
    "            print(f\"\\nДані для області ID={province}:\")\n",
    "            print(province_data.head())\n",
    "        else:\n",
    "            print(f\"\\nДля області ID={province} дані відсутні\")\n",
    "else:\n",
    "    print(\"Дані не знайдено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o Для всього набору даних виявити роки, протягом яких екстремальні\n",
    "посухи торкнулися більше вказаного відсотка областей по Україні (20%\n",
    "областей - 5 областей з 25). Повернути роки, назви областей з\n",
    "екстремальними посухами та значення VHI;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Виявити роки, коли посуха торкнулася >20% областей (VHI < 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отримання даних про екстремальну посуху...\n",
      "Знайдено 2 років з ≥5 провінціями (VHI < 15):\n",
      "[2000, 2007]\n",
      "\n",
      "Перші 10 записів:\n",
      "      Year  PROVINCE_ID    VHI\n",
      "949   2000           21  14.64\n",
      "950   2000           21  11.82\n",
      "951   2000           21  10.81\n",
      "952   2000           21  10.68\n",
      "953   2000           21  12.30\n",
      "954   2000           21  14.24\n",
      "7837  2007           26  14.98\n",
      "7838  2007           26  14.23\n",
      "7839  2007           26  13.79\n",
      "7840  2007           26  13.41\n",
      "\n",
      "Повна таблиця даних:\n",
      "       Year  PROVINCE_ID    VHI\n",
      "51228  2000            7  12.26\n",
      "51229  2000            7  11.28\n",
      "51230  2000            7  11.25\n",
      "51231  2000            7  11.38\n",
      "51232  2000            7  12.91\n",
      "...     ...          ...    ...\n",
      "7838   2007           26  14.23\n",
      "7839   2007           26  13.79\n",
      "7840   2007           26  13.41\n",
      "7841   2007           26  13.28\n",
      "7842   2007           26  14.36\n",
      "\n",
      "[88 rows x 3 columns]\n",
      "\n",
      "Статистика по роках:\n",
      "      Записи  Унікальні провінції\n",
      "Year                             \n",
      "2000      41                    6\n",
      "2007      47                    5\n"
     ]
    }
   ],
   "source": [
    "def get_extreme_drought_data(df, threshold=15, min_provinces=5, start_year=None, end_year=None, verbose=True):\n",
    "\n",
    "    # Перевірка колонок\n",
    "    required_cols = ['PROVINCE_ID', 'Year', 'VHI']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Відсутні колонки: {missing_cols}\")\n",
    "        return pd.DataFrame(columns=required_cols)\n",
    "    \n",
    "    # Фільтрація за роками\n",
    "    if start_year and end_year:\n",
    "        if start_year > end_year:\n",
    "            start_year, end_year = end_year, start_year\n",
    "        df = df[df['Year'].between(start_year, end_year)]\n",
    "    \n",
    "    # Знаходимо записи з екстремальною посухою\n",
    "    drought_data = df[df['VHI'] < threshold]\n",
    "    \n",
    "    if drought_data.empty:\n",
    "        print(f\"Не знайдено записів з VHI < {threshold}\")\n",
    "        return pd.DataFrame(columns=required_cols)\n",
    "    \n",
    "    # Визначаємо роки з достатньою кількістю провінцій\n",
    "    yearly_counts = drought_data.groupby('Year')['PROVINCE_ID'].nunique()\n",
    "    extreme_years = yearly_counts[yearly_counts >= min_provinces].index\n",
    "    \n",
    "    if not extreme_years.any():\n",
    "        print(f\"Не знайдено років з ≥{min_provinces} провінціями (VHI < {threshold})\")\n",
    "        return pd.DataFrame(columns=required_cols)\n",
    "    \n",
    "    # Фільтруємо дані для цих років\n",
    "    result = drought_data[drought_data['Year'].isin(extreme_years)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Знайдено {len(extreme_years)} років з ≥{min_provinces} провінціями (VHI < {threshold}):\")\n",
    "        print(sorted(extreme_years))\n",
    "        print(\"\\nПерші 10 записів:\")\n",
    "        print(result[['Year', 'PROVINCE_ID', 'VHI']].head(10))\n",
    "    \n",
    "    return result[['Year', 'PROVINCE_ID', 'VHI']].sort_values(['Year', 'PROVINCE_ID'])\n",
    "\n",
    "# Приклад використання\n",
    "print(\"Отримання даних про екстремальну посуху...\")\n",
    "drought_table = get_extreme_drought_data(\n",
    "    combined_data,\n",
    "    threshold=15,\n",
    "    min_provinces=5,\n",
    "    start_year=2000,\n",
    "    end_year=2020\n",
    ")\n",
    "\n",
    "if not drought_table.empty:\n",
    "    print(\"\\nПовна таблиця даних:\")\n",
    "    print(drought_table)\n",
    "    \n",
    "    # Додаткова статистика\n",
    "    print(\"\\nСтатистика по роках:\")\n",
    "    stats = drought_table.groupby('Year')['PROVINCE_ID'].agg(['count', 'nunique'])\n",
    "    stats.columns = ['Записи', 'Унікальні провінції']\n",
    "    print(stats)\n",
    "else:\n",
    "    print(\"Дані не знайдено\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
